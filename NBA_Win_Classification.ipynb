{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECE 196: NBA Win Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: Whenever you see '...', replace with a line of code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('NBA_Team_Data_18-19.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, our dataset is fairly clean in that our data is recorded with a consistent format.  Lets first check for any null values in our data. This is important because we cannot generate a model with null values.\n",
    "\n",
    "Hint: use .isnull() and .sum() to find the sum of null values in a given dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output a series with the column names of our dataframe and the sum of their null values\n",
    "... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'Season' column is the only column with null values.  All values are null, so we will drop the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets split our dataset into its features, X, and the label, y. Remember that our label is whether or not a team has won the game, this is in the 'W/L' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X should equal all of columns that are not 'W/L'\n",
    "X = ...\n",
    "# Y should equal the 'W/L' column\n",
    "y = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will get us more familiar with our dataset, as well as help with feature selection later on. In the cell below, we have found the indices of wins and losses, respectively.\n",
    "\n",
    "Using these indices, we will compare the distribution of the same variables when a team wins versus when they lose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wins = y[y==\"W\"].index\n",
    "losses = y[y==\"L\"].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate at least 3 sets of histograms, one set for each of the following columns in X: 'PTS', 'REB', and 'TOV'.  Each set should have two histograms, one filtered by when a team wins, and another filtered by when a team loses.\n",
    "\n",
    "Note: Your first plot will show up as blue, your second will be orange.\n",
    "\n",
    "Hint: Use .loc to select certain rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"PTS\") # Fill this in with the name of column you are plotting on the x-axis\n",
    "plt.ylabel(\"Count\") # The y-axis of a histogram should always be count, unless you are making a density plot\n",
    "\n",
    "### Plot two histograms of your target column: one filtered by wins and one filtered by losses ###\n",
    "...  # Plot histogram of 'PTS' column with data filtered by wins\n",
    "...  # Plot histogram of 'PTS' column with data filtered by losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"REB\") # Fill this in with the name of column you are plotting on the x-axis\n",
    "plt.ylabel(\"Count\") # The y-axis of a histogram should always be count, unless you are making a density plot\n",
    "\n",
    "### Plot two histograms of your target column: one filtered by wins and one filtered by losses ###\n",
    "...  # Plot histogram of 'REB' column with data filtered by wins\n",
    "...  # Plot histogram of 'REB' column with data filtered by losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"TOV\") # Fill this in with the name of column you are plotting on the x-axis\n",
    "plt.ylabel(\"Count\") # The y-axis of a histogram should always be count, unless you are making a density plot\n",
    "\n",
    "### Plot two histograms of your target column: one filtered by wins and one filtered by losses ###\n",
    "...  # Plot histogram of 'PTS' column with data filtered by wins\n",
    "...  # Plot histogram of 'PTS' column with data filtered by losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the distribution of 'TOV' is more even than the other two.  Lets look at the summary statistics for the 'TOV' column to find any difference in the distributions.\n",
    "\n",
    "Hint: Use .describe() to generate summary statistics for a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...  # Apply .describe on the 'TOV' column filtered by wins\n",
    "...  # Apply .describe on the 'TOV' column filtered by losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Extraction and Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some sense of what our data looks like and how distribution of columns differ when a team wins versus when they lose, lets try and select the most important features to predict whether or not a team will win.  Additionally, we can create derived features by forming combinations of our columns as we see fit, or turning categorical variables into vectors.\n",
    "\n",
    "This part is pretty open-ended, but I do have some tips.  Check out the ['Four Factors of Basketball Success'](https://www.basketball-reference.com/about/factors.html) by Dean Oliver.  He gives weights to the four most important factors that lead to a team winning.  Our model will create weights for us, but the features outlined in his four factors can be derived from our dataset.\n",
    "\n",
    "As a baseline model, try to input all quantitative columns into a kNN classifier and see what accuracy you are able to get.  Once you apply a model to all quantitative columns, come back to this part and see if you can improve your accuracy.  Machine Learning projects are an iterative process, meaning you should start with a baseline model and work your way up.\n",
    "\n",
    "Recommendation: Try to standardize all your columns and see if that improves accuracy over non-standardization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding Quantitative Columns:\n",
    "\n",
    "The cell below provides skeleton code for finding all quantitative columns.\n",
    "\n",
    "Hint: Use .dtype to find the datatype of a given column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_cols = []\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'int' or X[col].dtype == 'float':\n",
    "        quant_cols.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional**\n",
    "\n",
    "In the cell below, I will provide skeleton code for deriving a feature from our dataset.  In this example, we will be able to find whether a team is playing at Home or not based on the 'Match Up' column.  There are two types of outputs for this column: Case 1 -- 'Team_1 vs. Team_2' or Case 2 -- 'Team_1 @ Team_2'.  In Case 1, Team_1 is at home, whereas in Case 2, Team_1 is away.  \n",
    "\n",
    "We will utilize One Hot Encoding to separate 'Home' and 'Away' into two separate columns.\n",
    "\n",
    "Hint: Create a function to encode 'vs.' and '@' as 'Home' and 'Away' respectively for each row, then use df[column].apply(func) to apply your function to your Series.\n",
    "\n",
    "Hint: Use .split() to help isolate the 'vs.' and '@' characters.\n",
    "\n",
    "Hint: Use pd.get_dummies(df[column]) to One Hot Encode a given column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_home_away(row):\n",
    "    ### Insert code here: function should return either 'Home' or 'Away'\n",
    "    if ...:  # if we find 'vs.'\n",
    "        return 'Home'\n",
    "    if ...:  # if we find '@'\n",
    "        return 'Away'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_away = ... # Return a series of values that are either 'Home' or 'Away'. Use .apply\n",
    "home_away.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Match Up'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell has skeleton code for performing Logistic Regression on each quantitative variable and y. Use accuracy as a metric for determing which columns are most predictive towards success.  Feel free to use this once creating any derived features to check their effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feat = ... # Feature dataframe containing all the column we want to use so far\n",
    "#### Uncomment the line below if you created 'home_away' from above ###\n",
    "# X_feat[['Away', 'Home']] = ... # use pd.get_dummies to get these values\n",
    "model = ...  # Initiate a classification model, for example KNN, Logistic Regression, SVC, etc.\n",
    "             # refer to sklearn documntation for this...\n",
    "for col in X_feat:\n",
    "    ...  # Fit your newly initiated model to the column at X_feat and y\n",
    "    pred = ...  # Generate predictions based on the column at X_feat\n",
    "    print(\"{}:\".format(col))\n",
    "    print(\"Total Accuracy:\",sum(pred == y) / len(y))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add any additional feature engineering code here ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection and Performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have extracted all the features you wish to use in your Machine Learning model, it is time to select a model and test it's accuracy on unseen data.  Because we don't actually have unseen data, we will create a sample of our total dataset where we hold-out the labels.\n",
    "\n",
    "Using sklearn's train_test_split, create a testing and training set with 33% of our data going towards our test set.  Refer to sklearn [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to implement this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create X_train, X_test, y_train, and y_test with 33% of our total data in our test set\n",
    "... # Use train_test_split from sklearn to create X_train, X_test, y_train, and y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our training and testing datasets, we can initialize our classifier, fit to our training data, and make predictions on our testing data.  Pick whichever classifier you want, I have imported kNN, Logistic Regression, and SVM from sklearn.  You can find more classifiers on sklearn's website and import as you wish.\n",
    "\n",
    "Hint: Use .fit() and .predict() after initializing the classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ... # Initialize a classifier here\n",
    "## Fit and predict using X_train, y_train, and X_test\n",
    "... # Fit classifier to your X_train and y_train\n",
    "pred = ...  # Generate predictions based on X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline accuracy (using KNeighborsClassifier with k=5) was 0.73522. See if you can beat this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(pred == y_test) / len(pred)  # Outputs the accuracy of your predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have generated predictions and an accuracy from the model, change hyperparameters to improve model perfomance.  This may be changing the value of k for KNearestNeighbors, C for LogisticRegression and SVM, and others depending on your model.\n",
    "\n",
    "You could loop through existing hyperparameters and output the score for each one to find the optimal hyperparameter value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here: Hyperparameter Tuning ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "As you will see, it is fairly easy to get a score above 0.70 regardless of how much feature engineering we do or which classifier we choose.  However, we are sort of cheating in a sense, becuase we are using data from that game to predict the results of that game.\n",
    "\n",
    "An interesting extension of this problem would be to predict who will win a game WITHOUT having any statistics present from that game.  One way to approach this problem would be to find average statistics of the team's last 5 or so games, and use that to predict their performance in the current game.\n",
    "\n",
    "Additionally, we could find outside datasets, such as a dataset of Vegas odds for the game see who is favored to win.  The possibilities are endless as far as what features you could engineer to make more accurate predictions, as long as you have quality data and an open mind."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
